import os
from pathlib import Path
from threading import Lock
from typing import Iterable, Mapping

from snakemake.remote import AbstractRemoteProvider
from snakemake.utils import validate


#### Configuration ####
validate(config, schema="../schemas/config.schema.yml")  # also sets default values

glob_ext = config["sources"].get("glob_extension", ".tiff.c4gh")
if not glob_ext.startswith("."):
    raise ValueError("sources.glob_extension must start with a '.'")


#### Environment configuration ####
shell.prefix("set -o pipefail; ")
if workflow.use_singularity:
    # Bind mount the repository path into container.
    # Ideally we want to mount the repository in read-only mode.
    # To avoid making the working directory read-only should it be inside
    # or the same path as the working directory, we check for this case
    # and if true we mount read-write.
    repository = Path(config["repository"]["path"])
    work_dir = Path.cwd()
    if repository == work_dir or repository in work_dir.parents:
        mount_options = "rw"
    else:
        mount_options = "ro"
    workflow.singularity_args += (
        " --bind "
        f"{os.path.abspath(config['repository']['path'])}:"
        f"{os.path.abspath(config['repository']['path'])}:{mount_options}"
    )


##### Helper functions #####


def create_remote_provider(destination_config: Mapping[str, str]) -> AbstractRemoteProvider:
    """
    Create a snakemake remote provider from config["destination"].
    """
    # LP: The snakemake.remote.AutoRemoteProvider seems like the ideal solution
    # for the problem of easily mapping a destination type to a concrete
    # RemoteProvider class.  However, as of snakemake v6.12.3 I was not able to
    # get it work.  So, we provide our own implementation here.
    import importlib

    ProviderMap = {
        "azblob": "AzBlob",
        "dropbox": "dropbox",
        "ega": "EGA",
        "ftp": "FTP",
        "gfal": "gfal",
        "gridftp": "gridftp",
        "gs": "GS",
        "http": "HTTP",
        "irods": "iRODS",
        "ncbi": "NCBI",
        "s3": "S3",
        "sftp": "SFTP",
        "webdav": "",
        "xrootd": "XRootD",
    }

    destination_type = destination_config["type"].lower()
    module_name = f"snakemake.remote.{ProviderMap[destination_type]}"
    provider_module = importlib.import_module(module_name)
    return provider_module.RemoteProvider(**destination_config["connection"])


# Create the remote provider for the results.  This object is used by
# the get_remote function
RProvider = create_remote_provider(config["destination"])


def get_remote(path: str):
    destination_root = Path(config["destination"]["root_path"])
    return RProvider.remote(str(destination_root / path), **config["destination"]["connection"])


def get_repository_path() -> Path:
    return Path(config["repository"]["path"])


def glob_source_paths() -> Iterable[Path]:
    base_dir = get_repository_path()
    source_paths = [Path(p) for p in config["sources"]["items"]]
    if any(p.is_absolute() for p in source_paths):
        raise ValueError("Source paths must be relative to repository.path (absolute paths found).")
    # glob any directories for files that end with glob_ext
    try:
        cwd = os.getcwd()
        os.chdir(base_dir)
        source_files = [
            slide for p in source_paths if p.is_dir() for slide in p.rglob(f"*{glob_ext}")
        ] + [p for p in source_paths if p.is_file() and p.match("*.c4gh")]
    finally:
        os.chdir(cwd)
    return source_files


def get_all_new_item_names() -> Iterable[str]:
    """
    Returns a list with all the output (uuid) file names
    from the index generated by checkpoint rule gen_rename_index.

    Can only be used in `input:` sections as it accesses checkpoints.
    """
    with checkpoints.gen_rename_index.get().output.index.open() as f:
        return [line.split("\t", 1)[0] for line in f]


def get_original_item_name(new_name: str) -> str:
    """
    Reverse look-up on the rename index.  Given a "new" uuid4 name of a file
    this function retrieves the original name.

    Can only be used in `input:` sections as it accesses checkpoints.
    """
    global _gRenameIndexCache  # defined in index.smk
    with _gRenameIndexLock:
        if _gRenameIndexCache is None:
            with checkpoints.gen_rename_index.get().output.index.open() as f:
                # each line in the file is a tab-separated tuple (new name, original name)
                _gRenameIndexCache = dict(line.rstrip("\n").split("\t", 1) for line in f)
    return _gRenameIndexCache[new_name]


def get_original_file_path(new_filename: str) -> Path:
    """
    Given a "new" uuid4 name of a file, gets the path of the corresponding
    file in the repository.

    Can only be used in `input:` sections as it accesses checkpoints.
    """
    original_name = get_original_item_name(new_filename)
    full_path = get_repository_path() / original_name
    return full_path


##### Module-level name index cache #####

# The file renaming index is produced in a file (by the rules in index.smk),
# but then we need to look it up as a the workflow DAG is computed.  Rather
# than having to read the entire file for each look-up, we cache it in the
# module-level variable _gRenameIndexCache defined below.
#
# I don't know whether it's thread safe to access a global structure like this
# in snakemake rules.  Since I'm in doubt we'll protect write accesses with a
# threading.Lock

_gRenameIndexLock = Lock()
_gRenameIndexCache = None
